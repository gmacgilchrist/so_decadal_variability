{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster = SLURMCluster(queue='analysis', cores=4, project='gfdl_o',\n",
    "#                        memory=\"24GB\", walltime=\"00:30:00\",\n",
    "#                        scheduler_options={\"dashboard_address\": \"localhost:8726\"})\n",
    "cluster = SLURMCluster(queue='analysis', cores=4, project='gfdl_o',\n",
    "                       processes=1,\n",
    "                       memory=\"64GB\", walltime=\"00:30:00\",\n",
    "                       scheduler_options={\"dashboard_address\": \"localhost:8726\"})\n",
    "# cluster = LocalCluster(memory_limit=\"256GB\",\n",
    "#                        threads_per_worker=10,\n",
    "#                        n_workers=1,\n",
    "#                        dashboard_address=8726,\n",
    "#                        processes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://140.208.147.171/5767/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://140.208.147.171:8726/status' target='_blank'>http://140.208.147.171:8726/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>10</li>\n",
       "  <li><b>Memory: </b>256.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://140.208.147.171/5767/1' processes=1 threads=10, memory=256.00 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cluster.scale(8)\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decadal variability of WMT in OM4 hincast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from xgcm import Grid\n",
    "import glob\n",
    "import wmt_bgc.basic as wmt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifications for heat and salt budgets\n",
    "variables = {'heat':'thetao','salt':'so'}\n",
    "processes=['boundary forcing','vertical diffusion','neutral diffusion',\n",
    "           'frazil ice','internal heat']\n",
    "terms = {}\n",
    "terms['heat'] = {'boundary forcing':'boundary_forcing_heat_tendency',\n",
    "         'vertical diffusion':'opottempdiff',\n",
    "         'neutral diffusion':None,\n",
    "         'frazil ice':'frazil_heat_tendency',\n",
    "         'internal heat':None}\n",
    "terms['salt'] = {'boundary forcing':'boundary_forcing_salt_tendency',\n",
    "         'vertical diffusion':'osaltdiff',\n",
    "         'neutral diffusion':None,\n",
    "         'frazil ice':None,\n",
    "         'internal heat':None}\n",
    "# Additional variables to load\n",
    "extra = {}\n",
    "extra['surface'] = {'mass flux':'wfo'}\n",
    "extra['full'] = {'volume':'volcello'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "config = 'OM4p25_JRA55do1.4_0netfw_cycle6'\n",
    "rootdir = '/archive/Raphael.Dussin/xanadu_esm4_20190304_mom6_2019.08.08/'+config+'/gfdl.ncrc4-intel16-prod/pp/'\n",
    "years = '*'\n",
    "\n",
    "# 3D tendencies\n",
    "pp = 'ocean_annual_z'\n",
    "localdir = '/ts/annual/5yr/'\n",
    "filenames = []\n",
    "for variable in variables:\n",
    "    filenames.append(glob.glob(rootdir+pp+localdir+pp+'.'+years+'.'+variables[variable]+'.nc'))\n",
    "    for process in processes:\n",
    "        term = terms[variable][process]\n",
    "        if term is not None:\n",
    "            filenames.append(glob.glob(rootdir+pp+localdir+pp+'.'+years+'.'+term+'.nc'))\n",
    "# Additional 3D variables\n",
    "term=extra['full']['volume']\n",
    "filenames.append(glob.glob(rootdir+pp+localdir+pp+'.'+years+'.'+term+'.nc'))\n",
    "ds = xr.open_mfdataset(filenames)\n",
    "\n",
    "# Grid\n",
    "grid = xr.open_dataset(rootdir+pp+'/'+pp+'.static.nc')\n",
    "\n",
    "# gamma_n\n",
    "gammadir = '/archive/gam/so_decadal_variability/OM4p25_JRA55do1.4_0netfw_cycle6/'\n",
    "localdir = '/'\n",
    "ds = xr.merge([ds,xr.open_mfdataset(gammadir+pp+localdir+pp+'.'+years+'.gamma_n.nc')['gamma_n']])\n",
    "ds['gamma_n'] = ds['gamma_n'].where(ds['gamma_n']>0,np.nan)\n",
    "\n",
    "# Surface fluxes\n",
    "pp = 'ocean_monthly'\n",
    "localdir = '/ts/monthly/5yr/'\n",
    "term = extra['surface']['mass flux']\n",
    "filenames = glob.glob(rootdir+pp+localdir+pp+'.'+years+'.'+term+'.nc')\n",
    "ds_surf = xr.open_mfdataset(filenames)\n",
    "# Take annual means of surface flux data\n",
    "ds_surf_annual = ds_surf.groupby('time.year').mean('time').rename({'year':'time'}).assign_coords({'time':ds['time']})\n",
    "# Expand surface flux variable to 3D, with zeros everywhere except surface \n",
    "ds_surf_annual = ds_surf_annual.expand_dims({'z_i':ds['z_i']}).where(ds['z_i']==ds['z_i'][0],0)\n",
    "\n",
    "# Grab \n",
    "ds = xr.merge([ds,ds_surf_annual[term]])\n",
    "\n",
    "# Specify some constants\n",
    "Cp = 3992.\n",
    "rho0 = 1035."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.chunk({'time':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an xgcm grid object\n",
    "# Create a pseudo-grid in the vertical\n",
    "grid['z_l'] = ds['z_l']\n",
    "grid['z_i'] = ds['z_i']\n",
    "grid['dzt'] = grid['z_l'].copy(data=grid['z_i'].diff('z_i'))\n",
    "grid = grid.squeeze() # Get rid of any remnant time variables\n",
    "\n",
    "# Fill in nans with zeros\n",
    "grid['dxt'] = grid['dxt'].fillna(0.)\n",
    "grid['dyt'] = grid['dyt'].fillna(0.)\n",
    "grid['dzt'] = grid['dzt'].fillna(0.)\n",
    "grid['areacello'] = grid['areacello'].fillna(0.)\n",
    "grid['volcello'] = ds['volcello'].fillna(0.)\n",
    "metrics = {\n",
    "    ('X',): ['dxt','dxCu','dxCv'], # X distances\n",
    "    ('Y',): ['dyt','dyCu','dyCv'], # Y distances\n",
    "    ('Z',): ['dzt'], # Z distances\n",
    "    ('X', 'Y'): ['areacello'], # Areas\n",
    "    ('X', 'Y', 'Z'): ['volcello'], # Volumes\n",
    "}\n",
    "coords={'X': {'center': 'xh', 'right': 'xq'},\n",
    "        'Y': {'center': 'yh', 'right': 'yq'},\n",
    "        'Z': {'center': 'z_l', 'outer': 'z_i'} }\n",
    "xgrid = Grid(grid, coords=coords, metrics=metrics, periodic=['X'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pressure from depth\n",
    "ds['p'] = wmt.gsw_p_from_z(-ds['z_l'],grid['geolat'])\n",
    "ds['alpha'] = wmt.gsw_alpha(ds['so'],ds['thetao'],ds['p'])\n",
    "ds['beta'] = wmt.gsw_beta(ds['so'],ds['thetao'],ds['p'])\n",
    "\n",
    "# Tracer flux due to mass flux at ocean surface\n",
    "for variable in variables:\n",
    "    vari = variables[variable]\n",
    "    ds[vari+'_i'] = xgrid.interp(ds[vari],'Z',boundary='extrapolate').chunk({'z_i':-1})\n",
    "    if variable=='heat':\n",
    "        Jlmass = ds[extra['surface']['mass flux']]*(ds[vari+'_i']-ds[vari+'_i'])\n",
    "    elif variable=='salt':\n",
    "        Jlmass = ds[extra['surface']['mass flux']]*(ds[vari+'_i']-xr.zeros_like(ds[vari+'_i']))\n",
    "    ds[vari+'_massflux'] = xgrid.derivative(Jlmass,'Z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate $h\\dot{\\lambda}$ and $h\\dot{\\rho}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hldot={}\n",
    "hrhodot={}\n",
    "for variable in variables:\n",
    "    hldot[variable]=xr.Dataset()\n",
    "    hrhodot[variable]=xr.Dataset()\n",
    "    if variable=='heat':\n",
    "        drhodl = -ds['alpha']\n",
    "    elif variable=='salt':\n",
    "        drhodl = ds['beta']\n",
    "    vari = variables[variable]\n",
    "    for process in processes:\n",
    "        term = terms[variable][process]\n",
    "        if term is not None:\n",
    "            hldot[variable][process] = ds[term]\n",
    "            if variable=='salt': # Multiply by 1000 to convert to gkg-1\n",
    "                hldot[variable][process]*=1000\n",
    "            if variable=='heat': # Divide by Cp to get temperature tendency\n",
    "                hldot[variable][process]/=Cp\n",
    "            if process=='boundary forcing':\n",
    "                hldot[variable][process]-=ds[vari+'_massflux']*xgrid.get_metric(ds[vari+'_massflux'],'Z')\n",
    "            hrhodot[variable][process] = drhodl*hldot[variable][process]\n",
    "\n",
    "# Sum up contributions to total tendency\n",
    "# This is hacky, necessarily assumes that process not present in salt present in heat\n",
    "hrhodot['total'] = xr.Dataset()\n",
    "for process in processes:\n",
    "    if process in hrhodot['heat'].data_vars:\n",
    "        hrhodot['total'][process]=hrhodot['heat'][process]\n",
    "    if process in hrhodot['salt'].data_vars:\n",
    "        hrhodot['total'][process]+=hrhodot['salt'][process]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply precursors, select subregion, and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nbhome/gam/miniconda/envs/mom6-clean/lib/python3.8/site-packages/xgcm-0.4.0+18.ge0eae1e-py3.8.egg/xgcm/transform.py:227: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "/nbhome/gam/miniconda/envs/mom6-clean/lib/python3.8/site-packages/xgcm-0.4.0+18.ge0eae1e-py3.8.egg/xgcm/transform.py:227: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "/nbhome/gam/miniconda/envs/mom6-clean/lib/python3.8/site-packages/xgcm-0.4.0+18.ge0eae1e-py3.8.egg/xgcm/transform.py:227: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "/nbhome/gam/miniconda/envs/mom6-clean/lib/python3.8/site-packages/xgcm-0.4.0+18.ge0eae1e-py3.8.egg/xgcm/transform.py:227: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "/nbhome/gam/miniconda/envs/mom6-clean/lib/python3.8/site-packages/xgcm-0.4.0+18.ge0eae1e-py3.8.egg/xgcm/transform.py:227: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "/nbhome/gam/miniconda/envs/mom6-clean/lib/python3.8/site-packages/xgcm-0.4.0+18.ge0eae1e-py3.8.egg/xgcm/transform.py:227: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "/nbhome/gam/miniconda/envs/mom6-clean/lib/python3.8/site-packages/xgcm-0.4.0+18.ge0eae1e-py3.8.egg/xgcm/transform.py:227: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "/nbhome/gam/miniconda/envs/mom6-clean/lib/python3.8/site-packages/xgcm-0.4.0+18.ge0eae1e-py3.8.egg/xgcm/transform.py:227: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n"
     ]
    }
   ],
   "source": [
    "# bins\n",
    "bins=np.arange(26,28.5,0.1)\n",
    "# gamma_n to cell interfaces\n",
    "ds['gamma_n_i'] = xgrid.interp(ds['gamma_n'],'Z',boundary='extrapolate').chunk({'z_i':-1})\n",
    "ds['b'] = xr.ones_like(ds['gamma_n']) # HACK\n",
    "# Select subregion\n",
    "selection = {'yh':slice(-90,-30)}\n",
    "ds_subregion = ds.sel(selection)\n",
    "# Precursors\n",
    "precursor = (ds_subregion['gamma_n']+1000)*ds_subregion['b']\n",
    "\n",
    "#\n",
    "variables_now = ['heat','salt','total']\n",
    "\n",
    "hrhodot_on_gamma = {}\n",
    "for variable in variables_now:\n",
    "    hrhodot_subregion = hrhodot[variable].sel(selection)\n",
    "    hrhodot_on_gamma[variable]=xr.Dataset()\n",
    "    for process in processes:\n",
    "        if process in hrhodot_subregion.data_vars:\n",
    "            hrhodot_on_gamma[variable][process] = xgrid.transform(\n",
    "                precursor*hrhodot_subregion[process],'Z',target=bins,target_data=ds_subregion['gamma_n_i'],method='conservative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = {}\n",
    "for variable in variables_now:\n",
    "    G[variable] = xr.Dataset()\n",
    "    for process in processes:\n",
    "        if process in hrhodot_on_gamma[variable].data_vars:\n",
    "            G[variable][process] = (hrhodot_on_gamma[variable][process]*grid['areacello']).sum(['xh','yh'])/np.diff(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nbhome/gam/miniconda/envs/mom6-clean/lib/python3.8/site-packages/dask/array/numpy_compat.py:41: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nbhome/gam/miniconda/envs/mom6-clean/lib/python3.8/site-packages/dask/array/numpy_compat.py:41: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/nbhome/gam/miniconda/envs/mom6-clean/lib/python3.8/site-packages/dask/array/numpy_compat.py:41: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 4s, sys: 28min 20s, total: 53min 25s\n",
      "Wall time: 12min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outdir = '/work/gam/projects/so_decadal_variability/data/processed/'+config+'/'\n",
    "for variable in variables_now:\n",
    "    G[variable].to_netcdf(outdir+'G_'+variable+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
